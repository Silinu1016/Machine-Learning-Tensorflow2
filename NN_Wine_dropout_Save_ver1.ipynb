{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Lab 9 XOR\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "def min_max_scaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "\n",
    "xy1=pd.read_csv('datasets_Wine.csv')\n",
    "xy=xy1.values\n",
    "for i in range(0,xy.shape[0]):\n",
    "    if(xy[i][-1]=='good'):\n",
    "        xy[i][-1]=1\n",
    "    elif(xy[i][-1]=='bad'):\n",
    "        xy[i][-1]=0\n",
    "xy[:,:-1]=min_max_scaler(xy[:,:-1])\n",
    "test_line=int(len(xy)*0.7)\n",
    "x_data=xy[:test_line,:-1]\n",
    "y_data=xy[:test_line,[-1]] \n",
    "x_test=xy[test_line:,:-1]\n",
    "y_test=xy[test_line:,[-1]]\n",
    "x_data = np.array(x_data, dtype=np.float32) \n",
    "y_data = np.array(y_data, dtype=np.float32) \n",
    "x_test = np.array(x_test, dtype=np.float32) \n",
    "y_test = np.array(y_test, dtype=np.float32) \n",
    "X = tf.placeholder(tf.float32, [None,x_data.shape[1]])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-2-8dd83b9d3b6f>:6: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "W1 = tf.get_variable(\"W1\", shape=[x_data.shape[1], 100],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([100]))\n",
    "L1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[100,50],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([50]))\n",
    "L2 = tf.sigmoid(tf.matmul(L1, W2) + b2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[50,25],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([25]))\n",
    "L3 = tf.sigmoid(tf.matmul(L2, W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[25,10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "L4 = tf.sigmoid(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[10, 1],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([1]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "save_file = './train_model_Wine_dropout.ckpt'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7852982\n",
      "100 0.70489275\n",
      "200 0.69838613\n",
      "300 0.6954486\n",
      "400 0.6953344\n",
      "500 0.6953581\n",
      "600 0.6831794\n",
      "700 0.6194902\n",
      "800 0.56877863\n",
      "900 0.5577188\n",
      "1000 0.55295014\n",
      "1100 0.55956453\n",
      "1200 0.55328465\n",
      "1300 0.54265517\n",
      "1400 0.53648454\n",
      "1500 0.54242027\n",
      "1600 0.53660804\n",
      "1700 0.5352086\n",
      "1800 0.533715\n",
      "1900 0.5279314\n",
      "2000 0.54143625\n",
      "2100 0.5482939\n",
      "2200 0.520966\n",
      "2300 0.5315789\n",
      "2400 0.5375077\n",
      "2500 0.5325496\n",
      "2600 0.53639966\n",
      "2700 0.5172209\n",
      "2800 0.52797455\n",
      "2900 0.529128\n",
      "3000 0.532124\n",
      "3100 0.5358592\n",
      "3200 0.53879964\n",
      "3300 0.5248149\n",
      "3400 0.5155528\n",
      "3500 0.5287921\n",
      "3600 0.5209974\n",
      "3700 0.5478724\n",
      "3800 0.5187097\n",
      "3900 0.528836\n",
      "4000 0.52404565\n",
      "4100 0.51876503\n",
      "4200 0.52411985\n",
      "4300 0.5237874\n",
      "4400 0.5256538\n",
      "4500 0.5166913\n",
      "4600 0.52339876\n",
      "4700 0.52395386\n",
      "4800 0.52022547\n",
      "4900 0.52161515\n",
      "5000 0.5150092\n",
      "\n",
      "Hypothesis:\n",
      "[[ 2.7936065 ]\n",
      " [ 3.0136623 ]\n",
      " [ 2.895475  ]\n",
      " [ 2.9356406 ]\n",
      " [ 2.362885  ]\n",
      " [ 1.3678886 ]\n",
      " [ 2.7763748 ]\n",
      " [ 3.0352485 ]\n",
      " [ 1.0620843 ]\n",
      " [ 0.16178155]\n",
      " [ 0.60503274]\n",
      " [ 0.5269111 ]\n",
      " [-0.9519459 ]\n",
      " [ 3.0512683 ]\n",
      " [ 2.2345722 ]\n",
      " [ 2.9114723 ]\n",
      " [ 2.7482414 ]\n",
      " [ 1.8536642 ]\n",
      " [ 1.8536642 ]\n",
      " [-1.5090462 ]\n",
      " [-1.3755791 ]\n",
      " [-0.978281  ]\n",
      " [ 1.7887809 ]\n",
      " [ 2.5034213 ]\n",
      " [ 1.5196401 ]\n",
      " [ 0.5472081 ]\n",
      " [ 2.0744178 ]\n",
      " [ 0.40994278]\n",
      " [ 2.474557  ]\n",
      " [ 2.17348   ]\n",
      " [ 2.6903496 ]\n",
      " [ 3.0333235 ]\n",
      " [ 2.1382594 ]\n",
      " [-0.7410412 ]\n",
      " [ 1.9454666 ]\n",
      " [ 2.2104475 ]\n",
      " [-0.7410412 ]\n",
      " [ 2.8508384 ]\n",
      " [ 2.5980527 ]\n",
      " [ 1.8001668 ]\n",
      " [ 0.8037503 ]\n",
      " [ 1.9301288 ]\n",
      " [ 0.5581726 ]\n",
      " [ 2.9106104 ]\n",
      " [-0.38229516]\n",
      " [-0.38229516]\n",
      " [ 0.17235363]\n",
      " [ 0.4555191 ]\n",
      " [ 3.015319  ]\n",
      " [ 2.3874664 ]\n",
      " [ 1.701308  ]\n",
      " [ 1.0899203 ]\n",
      " [ 1.3037517 ]\n",
      " [ 2.8210208 ]\n",
      " [-0.46696505]\n",
      " [-0.46696505]\n",
      " [ 2.2606173 ]\n",
      " [ 0.26795512]\n",
      " [ 2.919903  ]\n",
      " [-0.33514413]\n",
      " [ 1.8795928 ]\n",
      " [ 1.8795928 ]\n",
      " [ 1.9886693 ]\n",
      " [ 2.1215792 ]\n",
      " [-1.3406153 ]\n",
      " [-1.2657415 ]\n",
      " [ 1.5189795 ]\n",
      " [ 1.7824899 ]\n",
      " [ 1.5189795 ]\n",
      " [-1.2657415 ]\n",
      " [-1.2601634 ]\n",
      " [ 2.6773765 ]\n",
      " [-0.60095704]\n",
      " [ 2.9856749 ]\n",
      " [-0.62899935]\n",
      " [-1.4670625 ]\n",
      " [-0.887869  ]\n",
      " [-1.6858525 ]\n",
      " [-0.41315827]\n",
      " [ 2.0215776 ]\n",
      " [-1.6858525 ]\n",
      " [-0.41315827]\n",
      " [ 2.01606   ]\n",
      " [ 2.5044987 ]\n",
      " [-1.501574  ]\n",
      " [ 2.0562382 ]\n",
      " [ 2.0562382 ]\n",
      " [ 2.0562382 ]\n",
      " [-0.38993236]\n",
      " [ 2.0562382 ]\n",
      " [ 2.2290154 ]\n",
      " [ 0.2673517 ]\n",
      " [-0.534922  ]\n",
      " [ 0.2673517 ]\n",
      " [ 1.2206374 ]\n",
      " [ 0.63326156]\n",
      " [ 2.5019205 ]\n",
      " [-1.368179  ]\n",
      " [ 2.9634197 ]\n",
      " [ 0.81551766]\n",
      " [ 2.3449228 ]\n",
      " [ 2.3871455 ]\n",
      " [ 2.3871455 ]\n",
      " [-1.5897126 ]\n",
      " [ 2.891324  ]\n",
      " [ 1.2822356 ]\n",
      " [-1.1411057 ]\n",
      " [-0.44997326]\n",
      " [-0.01069131]\n",
      " [ 3.0046766 ]\n",
      " [-0.79774725]\n",
      " [ 2.911057  ]\n",
      " [ 0.00581491]\n",
      " [-0.79774725]\n",
      " [ 0.38700646]\n",
      " [ 2.5300093 ]\n",
      " [ 1.0364293 ]\n",
      " [-0.146148  ]\n",
      " [ 2.5300093 ]\n",
      " [-0.8775821 ]\n",
      " [ 2.070877  ]\n",
      " [-1.3459305 ]\n",
      " [ 0.35623345]\n",
      " [ 2.8022747 ]\n",
      " [-1.4642303 ]\n",
      " [ 0.5765778 ]\n",
      " [ 0.40335178]\n",
      " [-1.0159965 ]\n",
      " [ 0.40335178]\n",
      " [ 2.0784152 ]\n",
      " [ 1.242238  ]\n",
      " [ 1.242238  ]\n",
      " [-0.42668924]\n",
      " [-0.68350637]\n",
      " [-0.51179636]\n",
      " [ 0.62667865]\n",
      " [ 0.513314  ]\n",
      " [-1.3845145 ]\n",
      " [ 0.33849275]\n",
      " [ 1.0582073 ]\n",
      " [ 1.0582073 ]\n",
      " [-2.4712107 ]\n",
      " [-0.33033803]\n",
      " [ 0.2653849 ]\n",
      " [-1.0288327 ]\n",
      " [ 2.8215446 ]\n",
      " [ 0.3479553 ]\n",
      " [ 0.3479553 ]\n",
      " [ 2.7460165 ]\n",
      " [-0.7858677 ]\n",
      " [ 3.0419571 ]\n",
      " [ 3.050817  ]\n",
      " [ 2.2709754 ]\n",
      " [ 1.9328287 ]\n",
      " [-0.80020213]\n",
      " [ 1.075438  ]\n",
      " [-1.5685277 ]\n",
      " [ 2.7636561 ]\n",
      " [-0.6738169 ]\n",
      " [-1.5685277 ]\n",
      " [ 2.6790326 ]\n",
      " [ 0.50851667]\n",
      " [ 0.50851667]\n",
      " [ 0.46037897]\n",
      " [-0.58576286]\n",
      " [ 1.3242837 ]\n",
      " [ 0.6592291 ]\n",
      " [ 3.0064936 ]\n",
      " [ 2.8760347 ]\n",
      " [-0.6107905 ]\n",
      " [-0.6107905 ]\n",
      " [ 0.45172685]\n",
      " [ 0.73544264]\n",
      " [ 2.939902  ]\n",
      " [-0.9104073 ]\n",
      " [ 0.73544264]\n",
      " [-1.0324306 ]\n",
      " [-1.0324306 ]\n",
      " [ 2.7196686 ]\n",
      " [ 2.5524693 ]\n",
      " [-1.4367727 ]\n",
      " [ 2.361735  ]\n",
      " [ 0.42025486]\n",
      " [ 2.5281277 ]\n",
      " [ 2.0056973 ]\n",
      " [-1.653492  ]\n",
      " [-1.5833867 ]\n",
      " [-1.4792655 ]\n",
      " [ 0.5369343 ]\n",
      " [-1.4792655 ]\n",
      " [-1.3787239 ]\n",
      " [-1.5833867 ]\n",
      " [ 2.944903  ]\n",
      " [-1.4655392 ]\n",
      " [ 0.12721655]\n",
      " [ 0.17128041]\n",
      " [-1.5624352 ]\n",
      " [ 1.9955714 ]\n",
      " [ 2.2610238 ]\n",
      " [-1.5624352 ]\n",
      " [-2.9837701 ]\n",
      " [-1.2112504 ]\n",
      " [ 1.8802494 ]\n",
      " [ 2.4760602 ]\n",
      " [ 2.3356478 ]\n",
      " [ 0.527709  ]\n",
      " [ 0.527709  ]\n",
      " [ 0.527709  ]\n",
      " [ 0.527709  ]\n",
      " [-0.99577916]\n",
      " [-1.5236914 ]\n",
      " [-1.5236914 ]\n",
      " [-2.4470105 ]\n",
      " [-0.06985477]\n",
      " [-1.277708  ]\n",
      " [-0.94954324]\n",
      " [ 2.8721118 ]\n",
      " [-0.63521826]\n",
      " [-0.63521826]\n",
      " [-0.63521826]\n",
      " [ 0.4969125 ]\n",
      " [ 0.4969125 ]\n",
      " [ 0.4969125 ]\n",
      " [ 0.41830742]\n",
      " [ 0.4969125 ]\n",
      " [ 0.9763529 ]\n",
      " [ 0.33003652]\n",
      " [ 1.0996606 ]\n",
      " [-0.9988946 ]\n",
      " [-0.9988946 ]\n",
      " [ 0.6612828 ]\n",
      " [-0.4967852 ]\n",
      " [ 1.5034096 ]\n",
      " [-0.7495332 ]\n",
      " [-0.7495332 ]\n",
      " [-0.29724494]\n",
      " [-0.36267582]\n",
      " [-0.4078639 ]\n",
      " [ 0.73969036]\n",
      " [-2.8237913 ]\n",
      " [ 0.42882758]\n",
      " [ 0.43846643]\n",
      " [-1.2631315 ]\n",
      " [ 0.42882758]\n",
      " [-1.4932473 ]\n",
      " [ 1.6163102 ]\n",
      " [-0.40616462]\n",
      " [-1.2040958 ]\n",
      " [-0.05635425]\n",
      " [-1.6059957 ]\n",
      " [-0.34884068]\n",
      " [-2.7813356 ]\n",
      " [ 2.0233462 ]\n",
      " [-2.7813356 ]\n",
      " [-2.7039158 ]\n",
      " [-1.2413073 ]\n",
      " [-1.4903731 ]\n",
      " [-1.2284639 ]\n",
      " [ 1.2087077 ]\n",
      " [-0.11898807]\n",
      " [ 0.6729372 ]\n",
      " [ 0.6729372 ]\n",
      " [-1.3188528 ]\n",
      " [-1.7291763 ]\n",
      " [-1.7291763 ]\n",
      " [-1.7968082 ]\n",
      " [-2.6379468 ]\n",
      " [-0.68968797]\n",
      " [-0.68968797]\n",
      " [-0.37334225]\n",
      " [-1.2312875 ]\n",
      " [ 2.8930955 ]\n",
      " [ 0.25309616]\n",
      " [-0.6471    ]\n",
      " [-0.34452102]\n",
      " [-1.5435266 ]\n",
      " [-0.5070152 ]\n",
      " [-0.39400062]\n",
      " [-1.6134524 ]\n",
      " [ 0.05492499]\n",
      " [ 1.0900266 ]\n",
      " [-2.9615498 ]\n",
      " [-2.9615498 ]\n",
      " [ 2.7325888 ]\n",
      " [ 1.593666  ]\n",
      " [ 0.1863837 ]\n",
      " [ 2.8807824 ]\n",
      " [ 2.771777  ]\n",
      " [ 2.2954457 ]\n",
      " [ 3.0447886 ]\n",
      " [ 2.2954457 ]\n",
      " [ 0.06314823]\n",
      " [ 0.39841968]\n",
      " [ 2.771777  ]\n",
      " [ 0.16514707]\n",
      " [ 0.35212374]\n",
      " [-0.10614416]\n",
      " [ 0.35212374]\n",
      " [ 2.9296691 ]\n",
      " [-0.3715724 ]\n",
      " [-2.5852578 ]\n",
      " [-0.3715724 ]\n",
      " [-0.3784962 ]\n",
      " [ 2.6069908 ]\n",
      " [ 0.8239474 ]\n",
      " [ 0.36513197]\n",
      " [ 0.36513197]\n",
      " [ 2.7654026 ]\n",
      " [ 1.084407  ]\n",
      " [ 0.8252494 ]\n",
      " [ 2.9094625 ]\n",
      " [ 0.4780816 ]\n",
      " [-0.8041755 ]\n",
      " [ 2.8068964 ]\n",
      " [ 0.4739372 ]\n",
      " [-0.63769674]\n",
      " [-0.63769674]\n",
      " [-2.6590343 ]\n",
      " [-0.53227353]\n",
      " [-0.127686  ]\n",
      " [ 0.40859914]\n",
      " [ 2.4157078 ]\n",
      " [-1.9149258 ]\n",
      " [ 0.1128042 ]\n",
      " [ 1.3808694 ]\n",
      " [ 0.4243268 ]\n",
      " [-1.8978164 ]\n",
      " [ 0.1128042 ]\n",
      " [-0.21330586]\n",
      " [ 0.2578918 ]\n",
      " [ 2.4554238 ]\n",
      " [ 2.4157078 ]\n",
      " [ 1.7283164 ]\n",
      " [ 2.6787658 ]\n",
      " [-2.0964818 ]\n",
      " [ 0.59396315]\n",
      " [-0.11985055]\n",
      " [ 0.31141222]\n",
      " [-2.0964818 ]\n",
      " [ 0.8517336 ]\n",
      " [ 3.0088868 ]\n",
      " [ 0.575921  ]\n",
      " [-0.8148228 ]\n",
      " [ 0.17509493]\n",
      " [ 0.34856522]\n",
      " [-0.108264  ]\n",
      " [-0.108264  ]\n",
      " [ 0.11345482]\n",
      " [-0.8913361 ]\n",
      " [ 0.11345482]\n",
      " [-1.5451932 ]\n",
      " [-0.48429832]\n",
      " [ 2.5394208 ]\n",
      " [ 1.5402677 ]\n",
      " [ 0.35475212]\n",
      " [-0.94062984]\n",
      " [ 2.9999921 ]\n",
      " [-0.94062984]\n",
      " [ 3.002765  ]\n",
      " [-0.7485349 ]\n",
      " [ 0.5587625 ]\n",
      " [-0.34367314]\n",
      " [ 0.5587625 ]\n",
      " [-0.7048609 ]\n",
      " [ 1.0402209 ]\n",
      " [-0.31099334]\n",
      " [-0.92140365]\n",
      " [-0.41336307]\n",
      " [ 0.5110159 ]\n",
      " [ 1.2946391 ]\n",
      " [ 0.9047662 ]\n",
      " [ 2.9499304 ]\n",
      " [ 1.2946391 ]\n",
      " [ 1.6813753 ]\n",
      " [-2.7358458 ]\n",
      " [ 1.0091294 ]\n",
      " [ 2.1417377 ]\n",
      " [-2.7358458 ]\n",
      " [ 0.9350312 ]\n",
      " [-0.41932258]\n",
      " [ 0.9350312 ]\n",
      " [-0.8226861 ]\n",
      " [-1.6156242 ]\n",
      " [-1.0107007 ]\n",
      " [ 0.6573492 ]\n",
      " [ 0.71644837]\n",
      " [-0.6262895 ]\n",
      " [ 0.08106101]\n",
      " [ 0.71644837]\n",
      " [ 0.5971781 ]\n",
      " [ 2.6843972 ]\n",
      " [ 0.4215312 ]\n",
      " [-0.16653755]\n",
      " [-0.1895878 ]\n",
      " [-0.00895584]\n",
      " [-1.9405491 ]\n",
      " [-1.9320006 ]\n",
      " [ 1.6930473 ]\n",
      " [ 1.2421957 ]\n",
      " [ 0.18140274]\n",
      " [-0.40508404]\n",
      " [ 1.2421957 ]\n",
      " [-1.1089164 ]\n",
      " [ 1.6930473 ]\n",
      " [ 0.32365376]\n",
      " [ 0.43019316]\n",
      " [ 0.19486755]\n",
      " [ 0.14218742]\n",
      " [ 1.2900472 ]\n",
      " [ 0.32264265]\n",
      " [ 0.22823685]\n",
      " [ 2.3504405 ]\n",
      " [-0.3546144 ]\n",
      " [ 0.40782768]\n",
      " [-1.6428251 ]\n",
      " [ 2.116074  ]\n",
      " [-0.34846005]\n",
      " [ 0.40734503]\n",
      " [ 0.14394343]\n",
      " [ 2.0086133 ]\n",
      " [ 0.38875246]\n",
      " [ 1.8574343 ]\n",
      " [ 2.1237102 ]\n",
      " [ 0.14815587]\n",
      " [ 0.781797  ]\n",
      " [ 2.5089965 ]\n",
      " [-0.45954558]\n",
      " [ 0.40185788]\n",
      " [ 2.1653988 ]\n",
      " [ 0.4866513 ]\n",
      " [ 2.6522045 ]\n",
      " [-0.8482666 ]\n",
      " [-0.8556721 ]\n",
      " [ 1.1407996 ]\n",
      " [-0.91054237]\n",
      " [ 0.15620759]\n",
      " [ 0.55720717]\n",
      " [-1.1259922 ]\n",
      " [ 0.15620759]\n",
      " [-3.2858229 ]\n",
      " [-2.557985  ]\n",
      " [-2.557985  ]\n",
      " [-2.557985  ]\n",
      " [-0.41930428]\n",
      " [-0.41930428]\n",
      " [-0.41930428]\n",
      " [ 1.5080721 ]\n",
      " [ 2.200144  ]\n",
      " [-0.41930428]\n",
      " [-0.8943316 ]\n",
      " [ 1.7471092 ]\n",
      " [ 2.843018  ]\n",
      " [ 2.2157643 ]\n",
      " [-2.8247805 ]\n",
      " [ 2.2335794 ]\n",
      " [ 0.3758933 ]\n",
      " [ 2.1336668 ]\n",
      " [ 1.3795696 ]\n",
      " [ 1.3784059 ]\n",
      " [ 0.70514923]\n",
      " [ 1.929148  ]\n",
      " [ 2.5663846 ]\n",
      " [ 1.929148  ]\n",
      " [ 1.1893563 ]\n",
      " [-1.5051309 ]\n",
      " [ 2.7686353 ]\n",
      " [ 2.445109  ]\n",
      " [ 2.7288082 ]\n",
      " [ 0.5727823 ]\n",
      " [ 2.3124905 ]\n",
      " [-1.8758283 ]\n",
      " [ 2.6792095 ]\n",
      " [ 0.5083566 ]\n",
      " [ 1.8548893 ]\n",
      " [ 0.11076295]\n",
      " [ 0.42841703]\n",
      " [ 2.124201  ]\n",
      " [ 1.8548893 ]\n",
      " [ 0.1981619 ]\n",
      " [ 1.1756498 ]] \n",
      "Predicted:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]] \n",
      "Accuracy:\n",
      "0.7291666865348816\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(5001):\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data,keep_prob:0.7})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, p, a = sess.run(\n",
    "        [hypothesis, predicted, accuracy], feed_dict={X: x_test, Y: y_test,keep_prob:1}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nHypothesis:\\n{h} \\nPredicted:\\n{p} \\nAccuracy:\\n{a}\")\n",
    "    saver.save(sess, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
