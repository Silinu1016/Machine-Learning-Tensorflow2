{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Lab 9 XOR\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "def min_max_scaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "\n",
    "xy1=pd.read_csv('datasets_Wine.csv')\n",
    "xy=xy1.values\n",
    "for i in range(0,xy.shape[0]):\n",
    "    if(xy[i][-1]=='good'):\n",
    "        xy[i][-1]=1\n",
    "    elif(xy[i][-1]=='bad'):\n",
    "        xy[i][-1]=0\n",
    "xy[:,:-1]=min_max_scaler(xy[:,:-1])\n",
    "test_line=int(len(xy)*0.7)\n",
    "x_data=xy[:test_line,:-1]\n",
    "y_data=xy[:test_line,[-1]] \n",
    "x_test=xy[test_line:,:-1]\n",
    "y_test=xy[test_line:,[-1]]\n",
    "X = tf.placeholder(tf.float32, [None,x_data.shape[1]])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\envs\\su\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "W1 = tf.Variable(tf.random_normal([x_data.shape[1], 100]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([100]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([100, 50]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([50]), name='bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([50, 25]), name='weight2')\n",
    "b3 = tf.Variable(tf.random_normal([25]), name='bias2')\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([25, 10]), name='weight2')\n",
    "b4 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "layer4 = tf.sigmoid(tf.matmul(layer3, W4) + b4)\n",
    "\n",
    "W5 = tf.Variable(tf.random_normal([10, 1]), name='weight4')\n",
    "b5 = tf.Variable(tf.random_normal([1]), name='bias4')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer4, W5) + b5)\n",
    "save_file = './train_model_Wine_without_dropout.ckpt'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9499935\n",
      "100 0.64953697\n",
      "200 0.61347455\n",
      "300 0.5875427\n",
      "400 0.5687715\n",
      "500 0.55415195\n",
      "600 0.5420388\n",
      "700 0.53169435\n",
      "800 0.5232079\n",
      "900 0.5170774\n",
      "1000 0.5128305\n",
      "1100 0.50978535\n",
      "1200 0.5074543\n",
      "1300 0.5055486\n",
      "1400 0.5039059\n",
      "1500 0.5024363\n",
      "1600 0.5010868\n",
      "1700 0.49982247\n",
      "1800 0.49861926\n",
      "1900 0.49746177\n",
      "2000 0.49634066\n",
      "2100 0.49525127\n",
      "2200 0.49419135\n",
      "2300 0.49315834\n",
      "2400 0.4921502\n",
      "2500 0.49116388\n",
      "2600 0.4901968\n",
      "2700 0.4892462\n",
      "2800 0.4883099\n",
      "2900 0.48738584\n",
      "3000 0.4864719\n",
      "3100 0.48556733\n",
      "3200 0.48467046\n",
      "3300 0.4837803\n",
      "3400 0.4828961\n",
      "3500 0.48201743\n",
      "3600 0.48114368\n",
      "3700 0.48027495\n",
      "3800 0.47941086\n",
      "3900 0.47855145\n",
      "4000 0.47769713\n",
      "4100 0.47684777\n",
      "4200 0.4760037\n",
      "4300 0.47516567\n",
      "4400 0.47433355\n",
      "4500 0.473508\n",
      "4600 0.47268957\n",
      "4700 0.47187844\n",
      "4800 0.471345\n",
      "4900 0.47584802\n",
      "5000 0.475895\n",
      "\n",
      "Hypothesis:  [[0.87115216]\n",
      " [0.96586674]\n",
      " [0.9147642 ]\n",
      " [0.91009057]\n",
      " [0.9186897 ]\n",
      " [0.8094362 ]\n",
      " [0.9404077 ]\n",
      " [0.95135736]\n",
      " [0.7858947 ]\n",
      " [0.59105986]\n",
      " [0.8120663 ]\n",
      " [0.79817486]\n",
      " [0.12388563]\n",
      " [0.9717045 ]\n",
      " [0.93146527]\n",
      " [0.94240963]\n",
      " [0.94301665]\n",
      " [0.876614  ]\n",
      " [0.876614  ]\n",
      " [0.18359223]\n",
      " [0.22883129]\n",
      " [0.29751956]\n",
      " [0.8894795 ]\n",
      " [0.86823225]\n",
      " [0.8202213 ]\n",
      " [0.6522336 ]\n",
      " [0.87316823]\n",
      " [0.83448267]\n",
      " [0.8532649 ]\n",
      " [0.91087395]\n",
      " [0.92805624]\n",
      " [0.959143  ]\n",
      " [0.86376536]\n",
      " [0.2850321 ]\n",
      " [0.89530647]\n",
      " [0.84858763]\n",
      " [0.2850321 ]\n",
      " [0.94021857]\n",
      " [0.9219835 ]\n",
      " [0.90418446]\n",
      " [0.83418596]\n",
      " [0.93122816]\n",
      " [0.8292389 ]\n",
      " [0.9620676 ]\n",
      " [0.47014597]\n",
      " [0.47014597]\n",
      " [0.6774444 ]\n",
      " [0.7227484 ]\n",
      " [0.96179295]\n",
      " [0.8844803 ]\n",
      " [0.83197534]\n",
      " [0.81007385]\n",
      " [0.86273575]\n",
      " [0.9451637 ]\n",
      " [0.44523308]\n",
      " [0.44523308]\n",
      " [0.8603479 ]\n",
      " [0.65048957]\n",
      " [0.9171237 ]\n",
      " [0.36196032]\n",
      " [0.89527345]\n",
      " [0.89527345]\n",
      " [0.86188567]\n",
      " [0.8917755 ]\n",
      " [0.16155729]\n",
      " [0.1649676 ]\n",
      " [0.80763626]\n",
      " [0.8878131 ]\n",
      " [0.80763626]\n",
      " [0.1649676 ]\n",
      " [0.18830428]\n",
      " [0.93647647]\n",
      " [0.43970394]\n",
      " [0.95393044]\n",
      " [0.43158102]\n",
      " [0.13659728]\n",
      " [0.30828294]\n",
      " [0.11597848]\n",
      " [0.33278537]\n",
      " [0.8782295 ]\n",
      " [0.11597848]\n",
      " [0.33278537]\n",
      " [0.86909413]\n",
      " [0.9197367 ]\n",
      " [0.22037321]\n",
      " [0.9241549 ]\n",
      " [0.9241549 ]\n",
      " [0.9241549 ]\n",
      " [0.7370224 ]\n",
      " [0.9241549 ]\n",
      " [0.93015444]\n",
      " [0.639997  ]\n",
      " [0.36749908]\n",
      " [0.639997  ]\n",
      " [0.8555722 ]\n",
      " [0.727685  ]\n",
      " [0.9411895 ]\n",
      " [0.15645576]\n",
      " [0.95307326]\n",
      " [0.8051753 ]\n",
      " [0.93761194]\n",
      " [0.94993794]\n",
      " [0.94993794]\n",
      " [0.17212442]\n",
      " [0.95584035]\n",
      " [0.86561704]\n",
      " [0.27829775]\n",
      " [0.30810297]\n",
      " [0.66053444]\n",
      " [0.9274124 ]\n",
      " [0.34929204]\n",
      " [0.94684505]\n",
      " [0.43347174]\n",
      " [0.34929204]\n",
      " [0.55877507]\n",
      " [0.8505825 ]\n",
      " [0.90849996]\n",
      " [0.6031129 ]\n",
      " [0.8505825 ]\n",
      " [0.32560378]\n",
      " [0.879706  ]\n",
      " [0.1316531 ]\n",
      " [0.58347476]\n",
      " [0.95031345]\n",
      " [0.18740237]\n",
      " [0.77598226]\n",
      " [0.7505549 ]\n",
      " [0.2163355 ]\n",
      " [0.7505549 ]\n",
      " [0.8972917 ]\n",
      " [0.8584691 ]\n",
      " [0.8584691 ]\n",
      " [0.43120897]\n",
      " [0.4380602 ]\n",
      " [0.48503846]\n",
      " [0.84343106]\n",
      " [0.6511644 ]\n",
      " [0.13617924]\n",
      " [0.5370907 ]\n",
      " [0.8636948 ]\n",
      " [0.8636948 ]\n",
      " [0.4013943 ]\n",
      " [0.44205302]\n",
      " [0.52303827]\n",
      " [0.2862836 ]\n",
      " [0.94652426]\n",
      " [0.72933227]\n",
      " [0.72933227]\n",
      " [0.9570641 ]\n",
      " [0.31668386]\n",
      " [0.9606988 ]\n",
      " [0.95787823]\n",
      " [0.8757479 ]\n",
      " [0.79040015]\n",
      " [0.2123406 ]\n",
      " [0.7916112 ]\n",
      " [0.10457945]\n",
      " [0.90934384]\n",
      " [0.4114083 ]\n",
      " [0.10457945]\n",
      " [0.9265362 ]\n",
      " [0.7071653 ]\n",
      " [0.7071653 ]\n",
      " [0.7650327 ]\n",
      " [0.37759885]\n",
      " [0.7882342 ]\n",
      " [0.78960085]\n",
      " [0.96123576]\n",
      " [0.88092756]\n",
      " [0.26339605]\n",
      " [0.26339605]\n",
      " [0.71219903]\n",
      " [0.84975255]\n",
      " [0.90390503]\n",
      " [0.30154026]\n",
      " [0.84975255]\n",
      " [0.18599811]\n",
      " [0.18599811]\n",
      " [0.9120287 ]\n",
      " [0.81467366]\n",
      " [0.14868575]\n",
      " [0.8010193 ]\n",
      " [0.727683  ]\n",
      " [0.91559815]\n",
      " [0.91071427]\n",
      " [0.08692369]\n",
      " [0.11920026]\n",
      " [0.25796056]\n",
      " [0.7378473 ]\n",
      " [0.25796056]\n",
      " [0.19944647]\n",
      " [0.11920026]\n",
      " [0.93345964]\n",
      " [0.14669466]\n",
      " [0.50811595]\n",
      " [0.515829  ]\n",
      " [0.10710859]\n",
      " [0.6632532 ]\n",
      " [0.92429304]\n",
      " [0.10710859]\n",
      " [0.19717658]\n",
      " [0.24295667]\n",
      " [0.6098457 ]\n",
      " [0.9324008 ]\n",
      " [0.9375416 ]\n",
      " [0.6832449 ]\n",
      " [0.6832449 ]\n",
      " [0.6832449 ]\n",
      " [0.6832449 ]\n",
      " [0.23960349]\n",
      " [0.11159807]\n",
      " [0.11159807]\n",
      " [0.08499941]\n",
      " [0.44169107]\n",
      " [0.20725492]\n",
      " [0.33429587]\n",
      " [0.9260248 ]\n",
      " [0.3191265 ]\n",
      " [0.3191265 ]\n",
      " [0.3191265 ]\n",
      " [0.76953006]\n",
      " [0.76953006]\n",
      " [0.76953006]\n",
      " [0.77280617]\n",
      " [0.76953006]\n",
      " [0.75107074]\n",
      " [0.56785786]\n",
      " [0.6886153 ]\n",
      " [0.2581429 ]\n",
      " [0.2581429 ]\n",
      " [0.80996203]\n",
      " [0.43497875]\n",
      " [0.7295804 ]\n",
      " [0.3892449 ]\n",
      " [0.3892449 ]\n",
      " [0.4700905 ]\n",
      " [0.30647498]\n",
      " [0.29672208]\n",
      " [0.7735317 ]\n",
      " [0.13647732]\n",
      " [0.5807719 ]\n",
      " [0.6773447 ]\n",
      " [0.23145577]\n",
      " [0.5807719 ]\n",
      " [0.11150286]\n",
      " [0.8275027 ]\n",
      " [0.5329025 ]\n",
      " [0.19225991]\n",
      " [0.44600418]\n",
      " [0.10094041]\n",
      " [0.34964252]\n",
      " [0.18910494]\n",
      " [0.95528114]\n",
      " [0.18910494]\n",
      " [0.07418901]\n",
      " [0.40110898]\n",
      " [0.09849447]\n",
      " [0.18357015]\n",
      " [0.7028134 ]\n",
      " [0.48475274]\n",
      " [0.81913733]\n",
      " [0.81913733]\n",
      " [0.13936895]\n",
      " [0.12592143]\n",
      " [0.12592143]\n",
      " [0.08460221]\n",
      " [0.07029098]\n",
      " [0.40661252]\n",
      " [0.40661252]\n",
      " [0.263862  ]\n",
      " [0.13479352]\n",
      " [0.89665294]\n",
      " [0.5317807 ]\n",
      " [0.29941028]\n",
      " [0.35991132]\n",
      " [0.12659144]\n",
      " [0.49201754]\n",
      " [0.53199476]\n",
      " [0.09345323]\n",
      " [0.64283866]\n",
      " [0.8469976 ]\n",
      " [0.06304488]\n",
      " [0.06304488]\n",
      " [0.92254627]\n",
      " [0.8368292 ]\n",
      " [0.5391278 ]\n",
      " [0.9434285 ]\n",
      " [0.9312465 ]\n",
      " [0.82558453]\n",
      " [0.9629713 ]\n",
      " [0.82558453]\n",
      " [0.45031756]\n",
      " [0.6399393 ]\n",
      " [0.9312465 ]\n",
      " [0.53793234]\n",
      " [0.6787138 ]\n",
      " [0.599694  ]\n",
      " [0.6787138 ]\n",
      " [0.94649816]\n",
      " [0.3905201 ]\n",
      " [0.07328779]\n",
      " [0.3905201 ]\n",
      " [0.48405284]\n",
      " [0.90948594]\n",
      " [0.86986434]\n",
      " [0.7196004 ]\n",
      " [0.7196004 ]\n",
      " [0.907015  ]\n",
      " [0.77000153]\n",
      " [0.84512734]\n",
      " [0.927423  ]\n",
      " [0.6884359 ]\n",
      " [0.21132714]\n",
      " [0.8598385 ]\n",
      " [0.6760699 ]\n",
      " [0.40805954]\n",
      " [0.40805954]\n",
      " [0.26171803]\n",
      " [0.27097857]\n",
      " [0.47392234]\n",
      " [0.64153135]\n",
      " [0.91789734]\n",
      " [0.07588303]\n",
      " [0.68818194]\n",
      " [0.72088844]\n",
      " [0.65071064]\n",
      " [0.07669291]\n",
      " [0.68818194]\n",
      " [0.57009655]\n",
      " [0.5696827 ]\n",
      " [0.91920507]\n",
      " [0.91789734]\n",
      " [0.88603485]\n",
      " [0.89985085]\n",
      " [0.11755306]\n",
      " [0.80490905]\n",
      " [0.45396376]\n",
      " [0.35577378]\n",
      " [0.11755306]\n",
      " [0.7789434 ]\n",
      " [0.954826  ]\n",
      " [0.70911324]\n",
      " [0.3045134 ]\n",
      " [0.6205195 ]\n",
      " [0.65704525]\n",
      " [0.4850023 ]\n",
      " [0.4850023 ]\n",
      " [0.47488475]\n",
      " [0.2940761 ]\n",
      " [0.47488475]\n",
      " [0.12659758]\n",
      " [0.32546592]\n",
      " [0.8863265 ]\n",
      " [0.91402805]\n",
      " [0.50513715]\n",
      " [0.34705406]\n",
      " [0.9503776 ]\n",
      " [0.34705406]\n",
      " [0.9508472 ]\n",
      " [0.26328892]\n",
      " [0.7871411 ]\n",
      " [0.38705903]\n",
      " [0.7871411 ]\n",
      " [0.33110434]\n",
      " [0.8080747 ]\n",
      " [0.39136142]\n",
      " [0.25852188]\n",
      " [0.34919035]\n",
      " [0.69546366]\n",
      " [0.5548341 ]\n",
      " [0.70559114]\n",
      " [0.95676506]\n",
      " [0.5548341 ]\n",
      " [0.66092527]\n",
      " [0.06549543]\n",
      " [0.75407016]\n",
      " [0.8999344 ]\n",
      " [0.06549543]\n",
      " [0.75170255]\n",
      " [0.38510036]\n",
      " [0.75170255]\n",
      " [0.31974024]\n",
      " [0.09679982]\n",
      " [0.2289016 ]\n",
      " [0.73961616]\n",
      " [0.8707271 ]\n",
      " [0.40213254]\n",
      " [0.54574883]\n",
      " [0.8707271 ]\n",
      " [0.78881985]\n",
      " [0.9407418 ]\n",
      " [0.64944965]\n",
      " [0.5929758 ]\n",
      " [0.49232125]\n",
      " [0.43840367]\n",
      " [0.10070002]\n",
      " [0.10155177]\n",
      " [0.80375624]\n",
      " [0.80477226]\n",
      " [0.62202495]\n",
      " [0.51241726]\n",
      " [0.80477226]\n",
      " [0.1999391 ]\n",
      " [0.80375624]\n",
      " [0.52271736]\n",
      " [0.6262181 ]\n",
      " [0.63146347]\n",
      " [0.6123011 ]\n",
      " [0.83865964]\n",
      " [0.63501465]\n",
      " [0.5392251 ]\n",
      " [0.86506283]\n",
      " [0.46527633]\n",
      " [0.73004997]\n",
      " [0.2265321 ]\n",
      " [0.8413923 ]\n",
      " [0.468651  ]\n",
      " [0.659852  ]\n",
      " [0.46940404]\n",
      " [0.85116863]\n",
      " [0.61079407]\n",
      " [0.8727608 ]\n",
      " [0.86111414]\n",
      " [0.53478056]\n",
      " [0.7635118 ]\n",
      " [0.9431593 ]\n",
      " [0.35241947]\n",
      " [0.7552924 ]\n",
      " [0.75603056]\n",
      " [0.7067888 ]\n",
      " [0.93364394]\n",
      " [0.37015513]\n",
      " [0.3670586 ]\n",
      " [0.8338481 ]\n",
      " [0.3423984 ]\n",
      " [0.5884186 ]\n",
      " [0.7440075 ]\n",
      " [0.2319544 ]\n",
      " [0.5884186 ]\n",
      " [0.09464714]\n",
      " [0.06816316]\n",
      " [0.06816316]\n",
      " [0.06816316]\n",
      " [0.40059352]\n",
      " [0.40059352]\n",
      " [0.40059352]\n",
      " [0.8472359 ]\n",
      " [0.94601583]\n",
      " [0.40059352]\n",
      " [0.36350137]\n",
      " [0.74385554]\n",
      " [0.9726745 ]\n",
      " [0.8256717 ]\n",
      " [0.06057698]\n",
      " [0.8493401 ]\n",
      " [0.63615584]\n",
      " [0.9078998 ]\n",
      " [0.94359696]\n",
      " [0.8341851 ]\n",
      " [0.8156057 ]\n",
      " [0.8035602 ]\n",
      " [0.9058759 ]\n",
      " [0.8035602 ]\n",
      " [0.69221604]\n",
      " [0.11910728]\n",
      " [0.9480587 ]\n",
      " [0.94345665]\n",
      " [0.9392879 ]\n",
      " [0.6607562 ]\n",
      " [0.9311609 ]\n",
      " [0.11565667]\n",
      " [0.92272395]\n",
      " [0.58118945]\n",
      " [0.8436753 ]\n",
      " [0.63926   ]\n",
      " [0.6487755 ]\n",
      " [0.7984508 ]\n",
      " [0.8436753 ]\n",
      " [0.5353808 ]\n",
      " [0.81450117]] \n",
      "Correct:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  0.7416667\n"
     ]
    }
   ],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(5001):\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, cost_val)\n",
    "    \n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run(\n",
    "        [hypothesis, predicted, accuracy], feed_dict={X: x_test, Y: y_test}\n",
    "    )\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
